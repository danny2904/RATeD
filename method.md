# Methodology: Uncertainty-Aware Cascaded Verification

The RATeD-V framework integrates a multitask training strategy with a cascaded verification pipeline. This architecture ensures that toxicity detection is both efficient and grounded in human-readable evidence.

---

## 3. Method

### 3.1. Multitask training methodology

Figure 1 illustrates the overall architecture of the proposed RATeD-V framework, highlighting the multitask transformer backbone and the rationale-guided fusion mechanism.

```mermaid
graph TD
    X[Input Text X] --> E[Transformer Encoder]
    E --> H[Contextual Repr. H]
    H --> BIO[BIO Tagging Head]
    H --> Fusion[Rationale-Guided Fusion]
    Fusion --> Z[Pooled Repr. Z]
    Z --> Cls[Classification Head]
    BIO -.->|Consistency Loss| Cls
```
*Figure 1: Overall architecture of RATeD-V featuring shared encoder and attention-based fusion.*

RATeD-V is built upon a unified multitask transformer backbone that jointly learns sentence-level toxicity detection and token-level toxic span extraction in a single training stage. Given an input sequence $X = \{x_1, \ldots, x_L\}$, a transformer encoder $E$ produces contextualized representations $H = \{h_1, \ldots, h_L\}$. Two task-specific heads are defined on top of the shared representations: a sentence classification head for predicting the toxicity label and a BIO-based sequence labeling head for identifying toxic spans.

The backbone is optimized using a joint objective that explicitly couples global predictions with token-level evidence:
$$\mathcal{L}_{total} = \lambda_1 \mathcal{L}_{cls} + \lambda_2 \mathcal{L}_{token} + \lambda_3 \mathcal{L}_{cons}$$
where $\mathcal{L}_{cls}$ denotes the sentence-level classification loss, $\mathcal{L}_{token}$ denotes the token-level BIO tagging loss, and $\mathcal{L}_{cons}$ enforces a consistency constraint between the sentence-level decision and the extracted rationale tokens.

To ensure that classification is grounded in explicit toxic evidence, RATeD-V incorporates a **Rationale-Guided Fusion** mechanism. An attention distribution $\alpha$ is computed over the contextual representations $H \in \mathbb{R}^{L \times d}$, and a rationale-aware sentence representation is obtained by attention pooling:
$$Z = \sum_{i=1}^{L} \alpha_i h_i$$
The pooled representation $Z$ is then used by the classification head, forcing the model to focus on span-level cues during decision making. This multitask formulation integrates toxic span extraction as a core component of the detection process rather than an auxiliary output.

---

### 3.2. Cascaded verification pipeline

The uncertainty-aware routing and the subsequent collaborative verification process are illustrated in Figure 2, detailing the dual-path inference workflow.

```mermaid
graph LR
    Input[Input X] --> B[Multitask Backbone]
    B --> Conf{Confidence C?}
    Conf -- "C âˆ‰ [Ï„_low, Ï„_high]" --> Fast[Fast Path: Final Results]
    Conf -- "C âˆˆ [Ï„_low, Ï„_high]" --> Judge[Judge Path]
    Judge --> RAG[LLM + Slang KB]
    RAG --> Union[Union Set Merging]
    Union --> Final[Validated Result]
```
*Figure 2: Cascaded inference workflow with confidence-gated routing and LLM-Judge verification.*

During inference, RATeD-V adopts a cascaded verification pipeline in which the multitask backbone acts as the primary predictor and a specialist LLM judge is selectively invoked for ambiguous cases. For a given input $X$, the backbone outputs a sentence-level posterior distribution $P(y \mid X)$, a set of predicted toxic spans $S_{backbone}$, and a confidence score defined as:
$$C = \max_y P(y \mid X)$$
An ambiguity region $\mathcal{U} = [\tau_{low}, \tau_{high}]$ is introduced to identify samples that require further verification. The routing policy is defined as:
$$ \text{Path}(X) = 
\begin{cases} 
\text{Fast Path} & \text{if } C \notin \mathcal{U} \\
\text{Judge Path} & \text{if } C \in \mathcal{U} 
\end{cases}
$$
Samples routed through the fast path are returned directly with the backbone predictions. In contrast, samples whose confidence lies inside the ambiguity region are forwarded to a collaborative verification stage with a specialist LLM judge. This uncertainty-aware gating mechanism allows RATeD-V to preserve the reliability of confident predictions while explicitly targeting linguistically complex or ambiguous cases for further inspection.

---

### 3.3. Collaborative verification mechanism

For samples satisfying $C \in \mathcal{U}$, RATeD-V activates a collaborative verification stage implemented by a specialist LLM-Judge ($M_{judge}$). In contrast to teacherâ€“student or post-hoc refinement settings, the LLM judge performs an **independent cross-validation** on the original input text $X$ and does not consume the backbone predictions or extracted spans. This design explicitly prevents error propagation from the backbone to the verification module.

To support reliable reasoning in highly informal and culturally nuanced social media contexts, RATeD-V incorporates a **Lightweight Retrieval-Augmented Prompting (RAG)** mechanism. A domain-specific **Slang Knowledge Base (K)** is constructed from the training and development splits by collecting high-frequency slang expressions, teencode patterns, and context-dependent toxic phrases.

Formally, the collaborative verification step is defined as:
$$(y_{judge}, S_{judge}) = M_{judge}(X, K)$$
The collaborative stage consists of two operations. First, the LLM-Judge independently validates the toxicity label based on the input text and the retrieved slang context. Second, it extracts an auxiliary set of toxic spans $S_{judge}$ that complements the backbone predictions. The final set of toxic spans is constructed by a union-based merging strategy:
$$S_{final} = (S_{backbone} \cup S_{judge}) \cdot \mathbb{1}(y_{judge} \neq \text{SAFE})$$
This union-set merging is intentionally adopted to preserve short, implicit, and context-dependent toxic expressions while retaining the backbone spans as stable anchors. The overall inference procedure is summarized in Algorithm 1.

```text
Algorithm 1: Rationale-Aware Cascaded Verification
-------------------------------------------------------------------------
Input:  Input Text X, Thresholds {Ï„_low, Ï„_high}, Slang KB K
Output: Final Label y*, Rationale Spans S*
-------------------------------------------------------------------------
1:  procedure RATeD-V_Inference(X, Ï„, K)
2:      # --------- Phase 1: Primary Inference & Gating ---------
3:      (y_b, S_b, C) â† M_backbone(X)             â–· Extract Confidence Score
4:      
5:      if C âˆ‰ [Ï„_low, Ï„_high] then return (y_b, S_b) â–· Fast-Path Bypass
6:      
7:      # --------- Phase 2: Collaborative Refinement ---------
8:      (y_j, S_j) â† M_judge(X, K)               â–· RAG-enhanced Validation
9:      S* â† (S_b âˆª S_j) Â· ðŸ™(y_j â‰  SAFE)         â–· Union-set Indicator Merging
10:     
11:     # --------- Final Decision ---------
12:     return (y_j, S*)
13: end procedure
-------------------------------------------------------------------------
```

---

## 4. Comparative Summary Table

| Feature                              | English (HateXplain) | Vietnamese (ViHOS)                    |
| :----------------------------------- | :------------------- | :------------------------------------ |
| **Model Backbone**                   | RoBERTa-base         | XLM-RoBERTa-base                      |
| **Ambiguity Region ($\mathcal{U}$)** | $[0.45, 0.98]$       | $C \in (Safe_{0.98}, Toxic_{0.90})^c$ |
| **Slang KB Source**                  | Mined (Train+Dev)    | Mined (Train+Dev)                     |
| **Refinement Logic**                 | 3-Class Re-labeling  | Binary Verification                   |

---

## 5. Experiments

### 5.1. Baselines

Äá»ƒ Ä‘Ã¡nh giÃ¡ **RATeD-V** dÆ°á»›i gÃ³c Ä‘á»™ há»‡ thá»‘ng trÃªn cáº£ hai ngÃ´n ngá»¯, chÃºng tÃ´i so sÃ¡nh framework vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p nháº­n diá»‡n Ä‘á»™c háº¡i (toxic identification) dá»±a trÃªn Encoder-based vÃ  LLM-based thÆ°á»ng Ä‘Æ°á»£c xem xÃ©t triá»ƒn khai thá»±c táº¿.

**Encoder-based Baselines:** NhÃ³m nÃ y bao gá»“m cÃ¡c mÃ´ hÃ¬nh Transformer SOTA Ä‘Æ°á»£c tinh chá»‰nh (fine-tuned) cho nhiá»‡m vá»¥ multitask (phÃ¢n loáº¡i cÃ¢u vÃ  trÃ­ch xuáº¥t báº±ng chá»©ng). 
- **Äá»‘i vá»›i tiáº¿ng Anh (English):** ChÃºng tÃ´i sá»­ dá»¥ng **RoBERTa (Base)** fine-tune trÃªn táº­p dá»¯ liá»‡u **HateXplain** lÃ m backbone cÆ¡ sá»Ÿ. 
- **Äá»‘i vá»›i tiáº¿ng Viá»‡t (Vietnamese):** ChÃºng tÃ´i sá»­ dá»¥ng **PhoBERT (Base) V2** vÃ  **XLM-RoBERTa (Base)** trÃªn táº­p dá»¯ liá»‡u **ViHOS**. 
NgoÃ i ra, cÃ¡c biáº¿n thá»ƒ Ä‘a ngÃ´n ngá»¯ vÃ  mÃ´ hÃ¬nh nÃ©n nhÆ° **mBERT** (Cased/Uncased) vÃ  **Distil-mBERT** cÅ©ng Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cáº£ hai táº­p dá»¯ liá»‡u Ä‘á»ƒ xem xÃ©t áº£nh hÆ°á»Ÿng cá»§a dung lÆ°á»£ng mÃ´ hÃ¬nh Ä‘áº¿n hiá»‡u nÄƒng trÃ­ch xuáº¥t rationale.

**LLM-based Baselines:** NhÃ³m thá»© hai bao gá»“m cÃ¡c LLM zero-shot Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ song song trÃªn cáº£ HateXplain vÃ  ViHOS. CÃ¡c há»‡ thá»‘ng thÆ°Æ¡ng máº¡i bao gá»“m **Gemini 2.5 Flash** vÃ  **GPT-4o-mini**, cÃ¹ng vá»›i mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ **Qwen2.5-7B-Instruct** Ä‘áº¡i diá»‡n cho cÃ¡c LLM cÃ³ thá»ƒ triá»ƒn khai cá»¥c bá»™. Máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh nÃ y cÃ³ kháº£ nÄƒng suy luáº­n máº¡nh máº½, chÃºng thÆ°á»ng gáº·p khÃ³ khÄƒn trong viá»‡c trÃ­ch xuáº¥t chÃ­nh xÃ¡c cÃ¡c span tá»« vá»±ng nháº¡y cáº£m trong ngÃ´n ngá»¯ khÃ´ng chÃ­nh thá»‘ng (informal text), Ä‘áº·c biá»‡t lÃ  vá»›i tiáº¿ng Viá»‡t. Má»™t baseline **Single-Stage (E1 Baseline)** cÅ©ng Ä‘Æ°á»£c Ä‘Æ°a vÃ o cho cáº£ hai ngÃ´n ngá»¯ Ä‘á»ƒ xÃ¡c láº­p ngÆ°á»¡ng hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh multitask gá»‘c khi khÃ´ng cÃ³ quy trÃ¬nh xÃ¡c thá»±c phÃ¢n táº§ng (no-verification conditions).

### 5.2. Evaluation Metrics

Do Ä‘áº·c thÃ¹ vá» cáº¥u trÃºc nhÃ£n vÃ  má»¥c tiÃªu nghiÃªn cá»©u cá»§a tá»«ng táº­p dá»¯ liá»‡u, chÃºng tÃ´i Ã¡p dá»¥ng cÃ¡c bá»™ chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ chuyÃªn biá»‡t cho tá»«ng ngÃ´n ngá»¯.

#### 5.2.1. English (HateXplain)
Bá»™ chá»‰ sá»‘ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng phÃ¢n loáº¡i 3 lá»›p (Hate, Offensive, Normal) vÃ  tÃ­nh cÃ´ng báº±ng:
- **Classification:** Sá»­ dá»¥ng **Accuracy** vÃ  **Macro-F1** cho bÃ i toÃ¡n 3 lá»›p. NgoÃ i ra, **AUROC** Ä‘Æ°á»£c tÃ­nh Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘á»™ tin cáº­y cá»§a xÃ¡c suáº¥t dá»± Ä‘oÃ¡n.
- **Explainability (ERASER):** Ãp dá»¥ng chuáº©n **Span IoU F1** vá»›i ngÆ°á»¡ng $\tau = 0.5$ vÃ  **Token mF1**. ChÃºng tÃ´i cÅ©ng bÃ¡o cÃ¡o **AUPRC** cho cÃ¡c token rationale Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng xáº¿p háº¡ng má»©c Ä‘á»™ Ä‘á»™c háº¡i cá»§a tá»«ng tá»«.
- **Fairness & Bias:** Sá»­ dá»¥ng **Generalized Mean Bias (GMB)** Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sá»± thiÃªn kiáº¿n Ä‘á»‘i vá»›i 11 nhÃ³m Ä‘á»‹nh danh (identity groups) nhÆ° *African, Arab, LGBTQ+*,... thÃ´ng qua giÃ¡ trá»‹ trung bÃ¬nh lÅ©y thá»«a (Power Mean) vá»›i $p = -5$.
- **Faithfulness** (Comprehensiveness & Sufficiency), Ä‘o lÆ°á»ng má»©c Ä‘á»™ sá»¥t giáº£m hiá»‡u nÄƒng khi loáº¡i bá» (masking) cÃ¡c rationale Ä‘Ã£ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n.
#### 5.2.2. Vietnamese (ViHOS)
Äá»‘i vá»›i tiáº¿ng Viá»‡t, chÃºng tÃ´i tuÃ¢n thá»§ cÃ¡c chuáº©n Ä‘o lÆ°á»ng cá»§a **ViHateT5** (Nguyen et al., 2024) vÃ  táº­p trung vÃ o Ä‘áº·c thÃ¹ ngÃ´n ngá»¯ Ä‘Æ¡n láº­p:
- **Classification:** Do ViHOS lÃ  bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n (Hate vs. Non-hate), bá»™ chá»‰ sá»‘ táº­p trung vÃ o **Accuracy, Precision, Recall** vÃ  **Macro-F1** á»Ÿ má»©c cÃ¢u.
- **Span Extraction (Character-level):** KhÃ¡c vá»›i tiáº¿ng Anh, viá»‡c trÃ­ch xuáº¥t báº±ng chá»©ng tiáº¿ng Viá»‡t Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ á»Ÿ **cáº¥p Ä‘á»™ kÃ½ tá»± (Character-level)** vá»›i chuáº©n hÃ³a **NFC** Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh chÃ­nh xÃ¡c cho cÃ¡c tá»« cÃ³ dáº¥u. ChÃºng tÃ´i bÃ¡o cÃ¡o **Accuracy, Character-level Macro F1** vÃ  **Weighted F1** cho tá»«ng cÃ¢u.

### 5.3. Sensitivity Analysis

The influence of the gating threshold $\tau$ on the classification performance and explainability of RATeD-V is illustrated in Figure 3. The multi-pane analysis demonstrates the trade-off between backbone efficiency and LLM reasoning across both English and Vietnamese datasets.

![Sensitivity Analysis](reports/figures/sensitivity_multi_pane.png)

*Figure 3: Influence of gating threshold $\tau$ on performance metrics (Accuracy, F1) and explainability (Span IoU/mF1) across Stage-2 inference.*

### 4.4. Impact of Rationale Supervision Weight ($\alpha$)

TrÃ¬nh bÃ y trong HÃ¬nh 4 lÃ  káº¿t quáº£ kháº£o sÃ¡t tÃ¡c Ä‘á»™ng cá»§a trá»ng sá»‘ giÃ¡m sÃ¡t rationale ($\alpha$) Ä‘á»‘i vá»›i táº­p dá»¯ liá»‡u English (HateXplain). Thá»­ nghiá»‡m nÃ y bÃ³c tÃ¡ch cÃ¡ch mÃ´ hÃ¬nh multitask pháº£n á»©ng khi thay Ä‘á»•i má»©c Ä‘á»™ Æ°u tiÃªn cá»§a viá»‡c trÃ­ch xuáº¥t span so vá»›i phÃ¢n loáº¡i cÃ¢u.

![Impact of Alpha](reports/figures/alpha_impact_en.png)

*Figure 4: Impact of Rationale Supervision Weight $\alpha$ on classification macro-F1, explainability (IoU F1, Token F1), and bias (GMB-Subgroup AUC) for HateXplain.*

Quan sÃ¡t cho tháº¥y giÃ¡ trá»‹ $\alpha$ Ä‘Ã³ng vai trÃ² quyáº¿t Ä‘á»‹nh trong viá»‡c kÃ­ch hoáº¡t kháº£ nÄƒng giáº£i thÃ­ch cá»§a mÃ´ hÃ¬nh. Táº¡i $\alpha=0$, máº·c dÃ¹ Ä‘á»™ chÃ­nh xÃ¡c phÃ¢n loáº¡i váº«n cao, nhÆ°ng mÃ´ hÃ¬nh gáº§n nhÆ° khÃ´ng thá»ƒ trÃ­ch xuáº¥t chÃ­nh xÃ¡c cÃ¡c báº±ng chá»©ng Ä‘á»™c háº¡i (IoU F1 $\approx 0.02$). Khi tÄƒng $\alpha$ lÃªn cÃ¡c ngÆ°á»¡ng tá»« $10^{-1}$ Ä‘áº¿n $10^1$, chÃºng ta tháº¥y sá»± cáº£i thiá»‡n Ä‘á»™t biáº¿n vá» cÃ¡c chá»‰ sá»‘ explainability trong khi váº«n báº£o toÃ n Ä‘Æ°á»£c tÃ­nh á»•n Ä‘á»‹nh cá»§a Macro F1 vÃ  kháº£ nÄƒng giáº£m thiá»ƒu bias (GMB AUC). Dá»± Ã¡n lá»±a chá»n $\alpha=10$ lÃ m tham sá»‘ tiÃªu chuáº©n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng tá»‘i Æ°u giá»¯a cÃ¡c má»¥c tiÃªu Ä‘a nhiá»‡m.

### 5.4. Ablation Study

Äá»ƒ Ä‘Ã¡nh giÃ¡ Ä‘Ã³ng gÃ³p Ä‘á»™c láº­p cá»§a cáº¥u trÃºc multitask vÃ  táº§ng xÃ¡c thá»±c phÃ¢n táº§ng, chÃºng tÃ´i thá»±c hiá»‡n thá»­ nghiá»‡m bÃ³c tÃ¡ch (Ablation Study) trÃªn ba cáº¥u hÃ¬nh. Äá»™ chÃ­nh xÃ¡c (**Accuracy**) Ä‘Æ°á»£c bÃ¡o cÃ¡o lÃ  chá»‰ sá»‘ phÃ¢n loáº¡i cáº¥p Ä‘á»™ cÃ¢u (Sentence-level Classification) trÃªn táº­p Test cá»§a hai táº­p dá»¯ liá»‡u:

1.  **Only Stage-1 (Backbone):** Chá»‰ sá»­ dá»¥ng mÃ´ hÃ¬nh encoder Ä‘Ã£ tinh chá»‰nh Ä‘a nhiá»‡m.
    *   **English:** `roberta-base` tinh chá»‰nh trÃªn HateXplain (Log: `experiments/english/baseline/results/RATeD_E1_baseline/`).
    *   **Vietnamese:** `xlm-roberta-base` tinh chá»‰nh trÃªn ViHOS (Log: `experiments/vietnamese/baseline/results/xlm-roberta-base/`).
2.  **Only Stage-2 (LLM Standalone):** Sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n á»Ÿ cháº¿ Ä‘á»™ Zero-shot (khÃ´ng tinh chá»‰nh).
    *   **English:** `Qwen2.5-7B-Instruct` (Log: `experiments/english/baseline/results/Qwen2_5_7B_Instruct/`).
    *   **Vietnamese:** `Qwen2.5-7B-Instruct` (Log: `experiments/vietnamese/baseline/results/Qwen2_5_7B_Instruct/`).
3.  **Both (Cascaded RATeD-V):** Há»‡ thá»‘ng Ä‘á» xuáº¥t Ä‘áº§y Ä‘á»§ káº¿t há»£p cáº£ hai giai Ä‘oáº¡n.
    *   **English:** TÃ­ch há»£p `roberta-base` vÃ  `Qwen-7B Specialist` (Log: `experiments/english/proposed/results/`).
    *   **Vietnamese:** TÃ­ch há»£p `xlm-roberta-base` vÃ  `Qwen-7B Specialist` (Log: `experiments/vietnamese/proposed/results/`).

Káº¿t quáº£ minh há»a táº¡i HÃ¬nh 4 kháº³ng Ä‘á»‹nh ráº±ng cÃ¡ch tiáº¿p cáº­n cascaded Ä‘áº¡t hiá»‡u suáº¥t cao nháº¥t Ä‘á»“ng nháº¥t trÃªn cáº£ hai ngÃ´n ngá»¯, Ä‘áº·c biá»‡t lÃ  vÆ°á»£t qua ngÆ°á»¡ng giá»›i háº¡n cá»§a LLM zero-shot thÃ´ng thÆ°á»ng.

![Ablation Study](reports/figures/ablation_study.png)

*Figure 5: Ablation study comparing the effectiveness of independent stages (Backbone vs. LLM) versus the proposed cascaded RATeD-V framework in term of Sentence-level Accuracy.*

---
> [!IMPORTANT]
> This hierarchical design ensures that the RATeD-V system remains robust against linguistic complexity (e.g., teencode, sarcasms) by leveraging LLM reasoning only when the base model exhibits high uncertainty.
